{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/likeshd/liks_NLP/blob/main/bert_finetune_text_classificattion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVLSDaWfdVoc"
      },
      "source": [
        "### Fine-tuning BERT for Phishing URL\n",
        "Here, we will walk through an example of BERT fine-tuning to classify phishing URLs. We will use the bert-base-uncased model freely available on the Hugging Face (HF) hub.\n",
        "\n",
        "The model consists of 110M parameters, of which we will only train a small percentage. Therefore, this example should easily run on most consumer hardware (no GPU required)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LxtOGGfSYahN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LOFtOJNgPUr"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install evaluate==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s01ijJ5NdUBh"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict, Dataset, load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import DataCollatorWithPadding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSDS7jgthpTo"
      },
      "source": [
        "the training dataset consists of 3,000 text-label pairs with a 70–15–15 train-test-validation split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dru2Ez82dUEt",
        "outputId": "ce831312-98d8-44b1-e55c-68cf77930b80"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "dataset_dict = load_dataset(\"shawhin/phishing-site-classification\")\n",
        "# dataset_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-VhKG7bh8YS"
      },
      "source": [
        "The Transformer library makes it super easy to load and adapt pre-trained models. Here’s what that looks like for the BERT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPcrV4z2dUHl",
        "outputId": "d3984e01-8cc0-40d2-97a0-45927abb1f30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# define pre-trained model path\n",
        "model_path = \"google-bert/bert-base-uncased\"\n",
        "\n",
        "# load model tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# load model with binary classification head\n",
        "id2label = {0: \"Safe\", 1: \"Not Safe\"}\n",
        "label2id = {\"Safe\": 0, \"Not Safe\": 1}\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path,\n",
        "                                                           num_labels=2,\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t_FZAZTicrZ"
      },
      "source": [
        "When we load a model like this, all the parameters will be set as trainable by default. However, training all 110M parameters will be computationally costly and potentially unnecessary.\n",
        "\n",
        "Instead, we can freeze most of the model parameters and only train the model’s final layer and classification head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Insl4sAldUKV"
      },
      "outputs": [],
      "source": [
        "# freeze all base model parameters\n",
        "for name, param in model.base_model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# unfreeze base model pooling layers\n",
        "for name, param in model.base_model.named_parameters():\n",
        "    if \"pooler\" in name:\n",
        "        param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgxxz8eHi863"
      },
      "source": [
        "Next, we will need to preprocess our data. This will consist of two key operations: tokenizing the URLs (i.e., converting them into integers) and truncating them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "06b9c87b0930488198951db62357ce4d",
            "ab241668107b45d186a7be7a9abf4952",
            "347774f3db5745dcb6a8f9c5688ef79e",
            "e1e79180a8e14370b40bbff4fb139f7e",
            "fb96b31f357040ceaa1fbbd67a285a04",
            "b3466b6ac61b411faa5ceaf65176d18f",
            "b632cdd6df994fe48b24f457d73f6a9f",
            "5c8a1be597f14a64b8d86421c488feb6",
            "6ed41381f4fc4af5998e6d1d4a570fd6",
            "903e87ebbb2040598727a793d512616b",
            "cf9aa8b7f3e440c0bc637b6de0cbc0e6"
          ]
        },
        "id": "_gIJ5b9ni-RQ",
        "outputId": "f46d820c-8f29-40ce-c9fd-392f36207e3f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06b9c87b0930488198951db62357ce4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# define text preprocessing\n",
        "def preprocess_function(examples):\n",
        "    # return tokenized text with truncation\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "# preprocess all datasets\n",
        "tokenized_data = dataset_dict.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR1BAIxykJey"
      },
      "source": [
        "Another important step is creating a data collator that will dynamically pad token sequences in a batch during training so they have the same length. We can do this in one line of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EXiRKYGi-Ud"
      },
      "outputs": [],
      "source": [
        "# create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rHS3iQVlfPM"
      },
      "source": [
        "s a final step before training, we can define a function to compute a set of metrics to help us monitor training progress. Here, we will consider model accuracy and AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F161HtWgi-X9"
      },
      "outputs": [],
      "source": [
        "# load metrics\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "auc_score = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    # get predictions\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # apply softmax to get probabilities\n",
        "    probabilities = np.exp(predictions) / np.exp(predictions).sum(-1,\n",
        "                                                                 keepdims=True)\n",
        "    # use probabilities of the positive class for ROC AUC\n",
        "    positive_class_probs = probabilities[:, 1]\n",
        "    # compute auc\n",
        "    auc = np.round(auc_score.compute(prediction_scores=positive_class_probs,\n",
        "                                     references=labels)['roc_auc'],3)\n",
        "\n",
        "    # predict most probable class\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    # compute accuracy\n",
        "    acc = np.round(accuracy.compute(predictions=predicted_classes,\n",
        "                                     references=labels)['accuracy'],3)\n",
        "\n",
        "    return {\"Accuracy\": acc, \"AUC\": auc}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "341ws2hwlq8L"
      },
      "source": [
        "Now, we are ready to fine-tune our model. We start by defining hyperparameters and other training arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X6FNfxplsLy"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "lr = 2e-4\n",
        "batch_size = 8\n",
        "num_epochs = 10\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"bert-phishing-classifier_teacher\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    logging_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiEk5aJKl45D"
      },
      "source": [
        "Then, we pass our training arguments into a trainer class and train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "80uaXsdXlsOe",
        "outputId": "fce761ca-3725-41a5-cc2c-a61f30fc336e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjDekZ3zmHEz"
      },
      "source": [
        "We can see above  that the training and validation loss are monotonically decreasing while the accuracy and AUC increase with each epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vAuOjsomPvX"
      },
      "source": [
        "As a final test, we can evaluate the performance of the model on the independent validation data, i.e., data not used for training or setting hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qp7pYXWlsR5"
      },
      "outputs": [],
      "source": [
        "# apply model to validation dataset\n",
        "predictions = trainer.predict(tokenized_data[\"validation\"])\n",
        "\n",
        "# Extract the logits and labels from the predictions object\n",
        "logits = predictions.predictions\n",
        "labels = predictions.label_ids\n",
        "\n",
        "# Use your compute_metrics function\n",
        "metrics = compute_metrics((logits, labels))\n",
        "print(metrics)\n",
        "\n",
        "# >> {'Accuracy': 0.889, 'AUC': 0.946}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zec2nkidUNF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-FbzVdHdUP9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOJhoEk5limt2JKL3j/13j",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06b9c87b0930488198951db62357ce4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab241668107b45d186a7be7a9abf4952",
              "IPY_MODEL_347774f3db5745dcb6a8f9c5688ef79e",
              "IPY_MODEL_e1e79180a8e14370b40bbff4fb139f7e"
            ],
            "layout": "IPY_MODEL_fb96b31f357040ceaa1fbbd67a285a04"
          }
        },
        "347774f3db5745dcb6a8f9c5688ef79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c8a1be597f14a64b8d86421c488feb6",
            "max": 450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ed41381f4fc4af5998e6d1d4a570fd6",
            "value": 450
          }
        },
        "5c8a1be597f14a64b8d86421c488feb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed41381f4fc4af5998e6d1d4a570fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "903e87ebbb2040598727a793d512616b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab241668107b45d186a7be7a9abf4952": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3466b6ac61b411faa5ceaf65176d18f",
            "placeholder": "​",
            "style": "IPY_MODEL_b632cdd6df994fe48b24f457d73f6a9f",
            "value": "Map: 100%"
          }
        },
        "b3466b6ac61b411faa5ceaf65176d18f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b632cdd6df994fe48b24f457d73f6a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf9aa8b7f3e440c0bc637b6de0cbc0e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1e79180a8e14370b40bbff4fb139f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_903e87ebbb2040598727a793d512616b",
            "placeholder": "​",
            "style": "IPY_MODEL_cf9aa8b7f3e440c0bc637b6de0cbc0e6",
            "value": " 450/450 [00:00&lt;00:00, 4950.20 examples/s]"
          }
        },
        "fb96b31f357040ceaa1fbbd67a285a04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}